U nastavku slijedi opis metoda učenja pretraživanja. Pristupi opisani u ovom
poglavlju zahtijevaju sljedeće.

\begin{itemize}

  \item \textbf{Dobru referentnu politiku.} Svi pristupi -- osim \textsc{LOLS} --
  zahtijevaju optimalnu referentnu politiku inače može doći do nakupljanja
  pogreške \engl{compounding error} i nekonzistentne redukcije;

  \item \textbf{Dobar binarni klasifikator.} Za učenje pretraživanja potrebno je
  efikasno rješenje za problem višerazredne klasifikacije osjetljive na trošak.
  Višerazredni klasifikator trebao bi za primjere kod kojih je definiran veliki
  trošak pokušati njih pravilno klasificirati. Ako se inače minimizira točnost
  klasifikatora, onda bi se kod klasifikatora osjetljivog na trošak trebao
  minimizirati ukupan zbroj trošaka svih primjera. U tom slučaju moguće je da će
  se smanjiti točnost na primjerima za koje je trošak mali, ali povećati na
  onima gdje je trošak velik. Koristeći težinsku redukciju \textsc{ovo} ili
  \textsc{ova} \engl{weighted all-pairs or one-against-all} iz
  \citep{beygelzimer2005error, beygelzimer2005weighted} u kombinaciji s
  \textit{costing} algoritmom iz \citep{zadrozny2003cost} moguće je koristiti
  bilo koji binarni klasifikator bez korigiranja izvornog koda klasifikatora.
  Moguće je koristiti i pravi višerazredni klasifikator osjetljiv na trošak bez
  navedenih tehnika redukcije;

  \item \textbf{Dobro definiranu funkciju gubitka.} Ona može biti definirana na
  cijeloj strukturi koju predviđamo. Na primjer, može se između predviđenog i
  pravog stabla računati \textunderscript{F}{1} gubitak. Između prevedenog i
  referentnog prijevoda može se koristiti BLEU mjera \engla{bilingual evaluation
  understudy}{BLEU}. Navedene funkcije gubitka nemaju dekompoziciju preko
  strukture odluka. Moguće je koristiti i funkcije poput Hammingovog gubitka.

\end{itemize}
