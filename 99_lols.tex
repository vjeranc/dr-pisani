Lokalno optimalno učenje pretraživanja \engl{locally optimal learning to search}
najnoviji je pristup i primjer je redukcije združenog učenja koja je
konzistentna s najmanje pretpostavki o raspoloživoj polici.

\cite{daume15lols} daju teoretsku i empirijsku potvrdu te redukcije združenog
pretraživanja. Izvedeni su pokusi na tri zadatka: višerazredna klasifikacija
osjetljiva na trošak \engl{cost-sensitive multiclass classification},
označavanje vrste riječi i ovisnosno parsanje. Zaključak je da algoritam
\textsc{LOLS} bez obzira na kvalitetu referentne police može postići rezultate
vrlo sličnima optimalnoj polici u slučaju da prostor pretraživanja dopušta
uspinjanje brdom.

\begin{algorithm}
\caption{Lokalno optimalno učenje pretraživanja (\textsc{lols})}\label{alg:lols}
\begin{algorithmic}[1]
\Require Skup podataka $\{x_i, y_i\}_{i=1}^N$ uzet iz distribucije $\mathcal{D}$
         i $\beta \geq 0$. %% -- parametar mješavine za rollout.
\State Inicijaliziraj policu $\hat{\pi}_1$.
\ForAll{$i \in \{1,2,\ldots,N\}$}
  \State Generiraj referentnu policu $\pi^{\text{ref}}$ temeljenu na $y_i$.
  \State Inicijaliziraj $\Gamma = \emptyset$. \Comment{skup primjera osjetljivih na trošak.}
  \ForAll{$t \in \{0,1,2,\ldots,T_i-1\}$}
    \State Primijeniti $t$ puta policu $\pi_{i}^{\text{in}} = \hat{\pi}_i$  i stići do $s_t$. \Comment{Rollin.} \label{alg:lols:learned}
    \ForAll{$a \in A(s_t)$}
      \State Neka je  $\pi_{i}^{\text{out}} = \pi^{\text{ref}}$ s vjerojatnošću $\beta$, inače $\hat{\pi}_i$.
      \State Procjeni trošak $c_{i,t}(a)$ koristeći $T-t-1$ puta policu $\pi_{i}^{\text{out}}$. \Comment{Rollout.} \label{alg:lols:mixture}
    \EndFor
    \State Generiraj vektor značajki $\phi(x_i, s_t)$.
    \State Postavi $\Gamma = \Gamma \cup \{\langle c_{i,t}, \phi(x_i, s_t) \rangle\}$.
  \EndFor
  \State $\hat{\pi}_{i+1} \gets \textsc{Train}(\hat{\pi}_i, \Gamma)$.
\EndFor
\State Vrati usrednjenu policu preko svih $\hat{\pi}_1, \hat{\pi}_2, \ldots, \hat{\pi}_N$.
\end{algorithmic}
\end{algorithm}

Iz pseudokoda algoritma \ref{alg:lols} možemo primijetiti veliku sličnost sa
\textsc{Searn} algoritmom \ref{searnalg}. Razlike su sljedeće:

\begin{itemize}
  \item model u slučaju algoritma \textsc{LOLS} moguće je učiti primjer po
  primjer (\textit{online});

  \item \textsc{Searn} zahtjeva čuvanje naučenih polica za svaki prolaz preko
  skupa za učenje jer se \emph{rollin} i \emph{rollout} izvršavaju koristeći
  mješavinu polica, dok \textsc{LOLS} koristi samo trenutno naučenu policu i
  referentnu policu;

  \item u slučaju algoritma \textsc{LOLS} nije potrebno da je referentna polica
  optimalna, a za \textsc{Searn} je taj uvjet obavezan inače postoji mogućnost
  da naučena polica neće imati svojstvo generalizacije.

\end{itemize}

Ova varijanta učenja pretraživanja koristi se za rješavanje problema u okviru
ovog rada.
