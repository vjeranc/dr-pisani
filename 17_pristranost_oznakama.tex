U strukturnom učenju moguća je pojava problema pristranosti oznakama \engl{label
bias}. Pojavljuje se kod modela koji moraju donositi niz odluka, ali zbog
nedovoljno informacija prijašnje odluke donesene su krivo i uzrokuju akumulaciju
pogreške \engl{compounding error}. Kako model dobro radi na skupu za učenje,
problem koji se pojavljuje imenovan je zbog pristranosti prema oznakama u skupu
za učenje. Modeli koji su lokalno normalizirani (Markovljev model maksimalne
entropije) pate od pristranosti, dok globalno normalizirani modeli (uvjetna
slučajna polja) nemaju taj problem. Bilo bi prikladno da je model u stanju
ispraviti neku prijašnju pogrešku s obzirom na nove spoznaje o ulazu, ali to s
lokalno normaliziranim modelima nije jednostavno. Postoji mogućnost dodavanja
većeg broja značajki koje bi lokalne odluke uzimale u obzir i/ili \textit{beam}
pretrage. Eksperimentalno je utvrđeno da se mogu naučiti lokalno normalizirani
modeli koji dobro rade, ali svejedno ne mogu dostići učinkovitost globalno
normaliziranih modela \citep{liang2008structure}. Razlika između globalne i
lokalne normalizacije je ta što prethodni za pojedinu odluku koristi informaciju
o globalnom gubitku preko cijele strukture, dok potonji samo informaciju o
lokalnom gubitku -- modeli koji se uče na jedan ili drugi način minimiziraju
istu funkciju gubitka, ali pitanje je koja će normalizacija rezultirati
konzistentnim modelom.

\citet*{lafferty2001conditional} i \citet*{leon1991approche} definiraju i
detaljno razrađuju problem pristranosti oznakama. Za noviji pregled o samom
problemu čitatelja se upućuje na \citep{andor2016globally}.

\citet*{lafferty2001conditional} eksperimentalno potvrđuju pojavu pristranosti,
a kao jedno od mogućih rješenja navode kolabiranje stanja u jedno. Navode da je
takva operacija specijalni slučaj \emph{determinizacije} koja, za slučaj
težinskog stroja s konačnim brojem stanja, nije uvijek moguća, a kad je moguća,
može dovesti do kombinatorijalne eksplozije. Za problem označavanja vrste riječi
konkretan postupak determinacije bio bi odlučivanje u jednom koraku oznaku za
trenutnu i sljedeću riječ (ili više sljedećih riječi). U tom slučaju bi se
izbjegla situacija u kojem se pogreška na pojedinoj riječi propagira na odluke
koje slijede. Postoji mogućnost da je za problem potrebno spojiti sva stanja u
jednu diskretnu odluku i time izbijeći pristranost, ali tako nešto nije
vremenski isplativo i zahtijeva veći skup za učenje. Drugo je rješenje početi
treniranje s potpuno povezanim modelom gdje bi učenje trebalo otkriti temeljnu
strukturu koja je prisutna u podlozi, ali šteta je unaprijed odbaciti znanje o
samoj strukturi -- kao što je lanac odluka kod označavanja vrste riječi.

Na slici \ref{fig:labelbias} prikazan je jednostavan primjer donošenja odluka.
Može se promatrati kao problem označavanja niza gdje je prva oznaka $S$ dana, a
za sljedeća dva koraka potrebno je odabrati između druge dvije oznake. Krenuvši
iz početnog stanja $S$ potrebno je odlučiti kojim bridom nastaviti dalje. Iz
podataka točan niz odluka rezultira nizom $y_z = SAD$. Prikazani vektori
značajki $\mathbf{\Phi}$ su reprezentacija stanja i opažanja pomoću koje bi
klasifikator trebao napraviti odluku. Očito klasifikator ne može razlikovati
između stanja $A$ i $B$ te odluku bira nasumično. Da su odluke spojene
(determinizacija) u $AC$, $AD$, $BE$ i $BF$ vjerojatno bi bilo moguće odabrati
onu točnu. U ovom slučaju korisno je razmotriti kako bi Markovljev model
maksimalne entropije naučio niz odluka. Prvo bi se konstruirao klasifikacijski
problem između $A$ i $B$, a nakon toga između $C$ i $D$. Ako se koristi običan
model maksimalne entropije za ove klasifikacijske probleme, onda bi naučen
vektor težina bio $\mathbf{w} = \langle 0,0,-1 \rangle$.

Ako se sada izvede pretraga koristeći naučene težine, moguće je da postupak neće
otkriti točan niz, ali očekivanje je da bar proizvede rezultat koji minimizira
očekivani gubitak. U prvom koraku potrebno je odabrati $A$ ili $B$. Kako naučene
težine ne omogućavaju razlikovanje između ta dva izbora -- skalarni produkt
$\mathbf{w} \cdot \mathbf{\Phi} = 0$ -- potrebno je napraviti nasumičan odabir.
Ako je odabran $A$, onda će u drugom koraku biti odabran $E$ i gubitak će
iznositi 0. Suprotno, ako je odabran $B$, onda će u drugom koraku biti odabran
$F$. Očekivani gubitak tada iznosi $50.5$, a ne $0.5$ -- toliko bi iznosio da se
umjesto $F$ odabere $E$. Ovaj primjer demonstrira razlog pojave pristranosti
oznakama i nedostatak modela koji koriste lokalnu normalizaciju za učenje.
Razlog zašto nije minimiziran očekivan gubitak je taj što se model trenira na
optimalnom putu koji postoji u podacima. Ako nikad nije odabrano stanje $B$ u
podacima, onda se težine uopće neće ažurirati za razlikovanje stanja $E$ i $F$.
\citet{kaariainen2006lower} pokazuje da donošenje krivih lokalnih odluka može
akumulirati Hammingov gubitak otprilike jednak polovici duljine niza odluka.
Očekivani gubitak koji ima linearnu ovisnost o duljini niza odluka nije
zadovoljavajuć.

\begin{figure}
  \centering
  \tikzstyle{lb}=[lightblue,draw,thick,fill=lightblue!40,circle,
  minimum size=7ex, inner sep=1pt,anchor=south]
  \tikzstyle{dg}=[darkgreen,draw,thick,fill=darkgreen!40,circle,
  minimum size=5ex, inner sep=1pt,anchor=south]
  \begin{tikzpicture}[
    >={Triangle[]}]
    \node[lb] (start) {$S$};
    \node[above right= 1cm and 3.5cm of start, lb] (a) {$A$};
    \node[below right= 1cm and 3.5cm of start, dg] (b) {$B$};
    \node[above right= 1cm and 3.75cm of a, dg] (c) {$C$};
    \node[below right= 0.5cm and 3.75cm of a, lb] (d) {$D$};
    \node[above right= 0.5cm and 3.85cm of b, dg] (e) {$E$};
    \node[below right= 1cm and 3.85cm of b, dg] (f) {$F$};

    \draw[->, line width=1.2pt] (start) to[bend left=70]  (a);
    \draw[->, line width=1.2pt] (start) to[bend right=50] (b);
    \draw[->, line width=1.2pt] (a) to[bend left=50]      (c);
    \draw[->, line width=1.2pt] (a) to[bend left]         (d);
    \draw[->, line width=1.2pt] (b) to[bend right]        (e);
    \draw[->, line width=1.2pt] (b) to[bend right=50]     (f);

    \node[right=of c] (loss1) {$y_z \in \mathcal{Y}, l(y_z) = 1$};
    \node[right=of d] (loss2) {$y_z \in \mathcal{Y}, l(y_z) = 0$};
    \node[right=of e] (loss3) {$y_z \in \mathcal{Y}, l(y_z) = 1$};
    \node[right=of f] (loss4) {$y_z \in \mathcal{Y}, l(y_z) = 100$};

    \node[left=0.05cm of a] (f1) {$\mathbf{\Phi} = \langle 1,0,0 \rangle$};
    \node[left=0.05cm of b] (f2) {$\mathbf{\Phi} = \langle 1,0,0 \rangle$};
    \node[left=0.05cm of c] (f3) {$\mathbf{\Phi} = \langle 0,1,0 \rangle$};
    \node[left=0.05cm of d] (f4) {$\mathbf{\Phi} = \langle 0,0,1 \rangle$};
    \node[left=0.05cm of e] (f5) {$\mathbf{\Phi} = \langle 0,1,0 \rangle$};
    \node[left=0.05cm of f] (f6) {$\mathbf{\Phi} = \langle 0,0,1 \rangle$};

    \draw[->, line width=1.2pt] (c) to (loss1);
    \draw[->, line width=1.2pt] (d) to (loss2);
    \draw[->, line width=1.2pt] (e) to (loss3);
    \draw[->, line width=1.2pt] (f) to (loss4);

  \end{tikzpicture}
  \caption[Prikaz problema pristranosti oznaka.]{Prikaz problema pristranosti
  oznaka. Primjer preuzet iz \citep[str.~31]{daume06thesis}.}
  \label{fig:labelbias}
\end{figure}

Korisno je pogledati kako metode učenja pretraživanja razrješavaju problem, ali
bez potrebe dinamičkog programiranja ili aproksimacije particijske funkcije. Kod
algoritma \textsc{Searn} (alg.~\ref{alg:searn}) prvi će prolaz rezultirati
težinama kao i kod Markovljevog modela maksimalne entropije. Drugi prolaz preko
podataka koristit će interpolaciju naučene politike i optimalne politike što znači
da postoji mogućnost da se odabere stanje $B$, a onda dodatno nauči razlikovanje
između $E$ i $F$. Kod algoritma \textsc{LOLS} (alg.~\ref{alg:lols}) uči se
koristeći naučenu politiku od samog početka (početna politika je nasumična) što
garantira nailaženje na stanja koja ne postoje u podacima za učenje, a na kojima
onda referentna politika može naučiti razlikovati bolje odluke od lošijih. Ako
referentna politika nije dovoljno dobra, onda će sama procjena o gubitku tijekom
\textit{rollout} faze utjecati na razlikovanje između odluka. Detaljnije
razmatranje postupka učenja prisutno je u potpoglavlju \ref{ch:rollinrollout}.

\citet{andor2016globally} pretpostavljaju da je problem ovisnosnog parsiranja
vrlo težak upravo zbog pristranosti oznakama. Koristeći sve pristupe za koje se
pokazalo da dobro rješavaju problem pristranosti oznakama -- velika količina
značajki, bogata vektorska reprezentacija koju omogućava obična višeslojna mreža
bez povratnih veza, globalna normalizacija i \textit{beam} pretraga -- ostvarili
su najbolji rezultat na tom zadatku.
