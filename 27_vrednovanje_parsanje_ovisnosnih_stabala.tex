Za vrednovanje učinkovitosti koristi se mjera točnosti \engl{accuracy}. Koristi
se mjera bez oznaka \engla{unlabeled attachment score}{uas} za stablo koje nema
označene bridove. Ako su usmjereni bridovi označeni, onda se koristi mjera
točnost uzimajući oznake u obzir \engla{labeled attachment score}{las}. Za
usporedbu se koriste rezultati dobiveni u \citep{agic2013three}, koji su dobiveni
označivačem MSTParser. Vrednovanje se vrši na testnom skupu u formatu CoNLL-U.\footnote{Datoteka \texttt{hr-ud-test.conllu} raspoloživa na poveznici
\url{https://github.com/UniversalDependencies/UD_Croatian}} Rezultati nisu
usporedivi na zadatku gdje se označavaju bridovi jer se koristi drugi podatkovni
skup za MSTParser. Taj podatkovni skup ima samo 15 oznaka dok korišteni skup ima
32. Zbog toga bi problem označavanja UD skupa trebao biti teži. Oba skupa imaju
iste rečenice i ista ovisnosna stabla bez oznaka, a testni skup prikazan u
tablicama je spojen \textsc{SETimes} i \textsc{Wiki}.

Korištene značajke uključuju sufikse i prefikse do najveće duljine od pet
znakova. To su jedine značajke koje je moguće kontrolirati izvan algoritma.
Model nakon treniranja koristi više od milijardu zasebnih značajki (svaki
jedinstveni sufiks i prefiks i interne značajke su u tom broju), dok je npr.~za
označavanje vrste riječi taj broj oko 40 milijuna. Za pregled ostalih internih
značajki čitatelja se upućuje na \citep{chang2015learning}. Kako je model
prevelik, koristi se neuronska mreža s jednim skrivenim slojem od pet čvorova, a
za regularizaciju se koristi postupak prati-regulariziranog-vođu \engla{follow
the regularized leader}{ftrl}, koji uključuje L1 i L2 regularizaciju. Algoritam
\textsc{ftrl} postupak je regularizacije koji dopušta učenje primjer po primjer.
Kao kod ostalih algoritama \textsc{ftl}, tijekom učenja nastaje više mogućih
hipoteza (vektora težina za završni model) i vrši se odabir hipoteze koja za
dani primjer daje najbolje predviđanje (skalarni produkt između težina hipoteze
i vektora značajki koji daje najveću vrijednost). Nakon što je vođa odabran
njegove se težine ažuriraju s regularizacijskim pravilom, gdje nastaje nova
hipoteza, i postupak se ponavlja. Prikazani rezultati koriste navedenu
konfiguraciju, inače bi rezultati bili lošiji jer je skup za učenje premali s
obzirom na broj značajki. \citet{chang2015learning} ne koriste sufikse i
prefikse jer rade označavanje na jezicima koji imaju dovoljno podataka --
značajke su samo cijele riječi i oznaka vrste riječi.

U tablici \ref{table:depparsing} prikazani su rezultati. Kako morfosintaktički
deskriptori sadrže informaciju o sintaksi očekivano je da njihovo korištenje
poboljšava učinkovitost oba pristupa. Razlog zašto je \textsc{Vwdep} bolji jest
zbog superiornijeg algoritma. \citet{cer2010parsing} dobivaju slične razlike
između pristupa baziranog na minimalnom razapinjućem stablu i tranzicijskog
parsera. Prikazani rezultati su optimistični jer pretpostavljaju točne oznake
vrste riječi kao ulaz, ali označivač vrste riječi razvijen u okviru ovog rada
dovoljno je točan da nema bitne razlike između parsera koji koristi zlatne
oznake.

\begin{table}
\centering
\caption{Rezultat ovisnosnog parsanja.}
\label{table:depparsing}
\begin{tabular}{|l|c|c|}
\hline
Metoda                                & \textsc{las}   & \textsc{uas}    \\ \hline \hline
MSTParser (POS) \citep{agic2013three} & 74.56          & 81.59           \\
MSTParser (MSD) \citep{agic2013three} & 77.49          & 83.58           \\
\textsc{Vwdep} (POS)                  & 74.91          & 83.17           \\
\textsc{Vwdep} (MSD)                  & \textbf{79.22} & \textbf{86.44}  \\ \hline
\end{tabular}
\end{table}
